% Copyright 2024-2025 Kieran W Harvie. All rights reserved.

\section{Coordinate Free Determinant}
I've spent some time try to find a deeper definition of the determinant and was shown its coordinate free definition using the exterior product.
\\

Let $\phi:V\rightarrow V$ be a linear transform of the vector space $V$ over the field $F$ with dimension $n$.
$\phi$ induces a linear transform on $\bigwedge^k(V)$ given by:
\[\begin{aligned}
	\Lambda(\phi):\bigwedge\nolimits^k(V)\rightarrow\bigwedge\nolimits^k(V)\\
	\bigwedge^k_{l=1}v_l \mapsto \bigwedge^k_{l=1}\phi(v_l)
\end{aligned}\]
The key observation is that the dimension of $\bigwedge^k(V)$ is given by:
\[\dim\left(\bigwedge\nolimits^k(V)\right) = \binom{n}{k}\]
Hence when $n=k$ the dimension is $1$ and the only linear functions are characterized by a single scalar $\lambda \in F$ such that:
\[\Lambda(\phi)\left(\bigwedge^n_{l=1}v_l\right) = \lambda\left(\bigwedge^n_{l=1}v_l\right)\]
And this scalar is the determinant.

\subsection{Sum and Products}
I'm going to take a detour from showing that the this scalar is the determinant because I wish to jot down some useful formulae while they're fresh in my mind.
\\

Let $A_{i,j}$ be an array of vectors indexed by $I\times J$,
since the exterior product distributes over addition we get the regular combinatoric result for the (exterior) product of multinomials\footnote{Writing this is when using $J^I$ to mean the set of functions from $I$ to $J$ finally clicked.}:
\[\bigwedge_{i\in I}\sum_{j\in J} A_{i,j} = \sum_{\sigma\in J^I}\bigwedge_{i\in I}A_{i,\sigma(i)}\]
If $A_{i,j}$ can we written in terms of vectors $u_j$ and scalars $a_i^j$ as: 
\[A_{i,j} = a_i^ju_j\]
We get:
\[ \sum_{\sigma\in J^I}\bigwedge_{i\in I}A_{i,\sigma(i)} = \sum_{\sigma\in J^I}\left(\prod_{i\in I}a_i^{\sigma(i)}\right)\bigwedge_{i\in I}u_{\sigma(i)}\]
Note that exterior product factor is zero if $\sigma$ isn't injective so the sum can be restricted to just the injective elements of $J^I$.
It's cumbersome to write down this injective restriction in general,
but easy when $I$ and $J$ are equal and finite!
As it is simply $S_I$,
the in symmetric group on $I$.
\[\begin{aligned} 
	\sum_{\sigma\in I^I}\left(\prod_{i\in I}a_i^{\sigma(i)}\right)\bigwedge_{i\in I}u_{\sigma(i)}
	&= \sum_{\sigma\in S_I}\left(\prod_{i\in I}a_i^{\sigma(i)}\right)\bigwedge_{i\in I}u_{\sigma(i)}\\
	&= \sum_{\sigma\in S_I}\sgn(\sigma)\left(\prod_{i\in I}a_i^{\sigma(i)}\right)\bigwedge_{i\in I}u_{i}\\
\end{aligned}\]
Combining everything gives:
\[\bigwedge_{i\in I}\sum_{j\in J} a_i^ju_j= \sum_{\sigma\in S_I}\sgn(\sigma)\left(\prod_{i\in I}a_i^{\sigma(i)}\right)\bigwedge_{i\in I}u_{i}\]

\subsection{Leibniz's Formula}
Given a base $e_i$ indexed by $I$ our normal formula for the determinant is written in term of scalars $\phi_i^j$ such that:
\[\phi(e_i) = \sum_{j\in I}\phi_i^je_j\]
Substitution into our definition of $\Lambda(\phi)$ gives:
\[\Lambda(\phi)\left(\bigwedge_{i\in I}e_i\right) = \bigwedge_{i\in I}\phi(e_i) = \bigwedge_{i\in I}\sum_{j\in J}\phi_i^je_j\]
Applying the final result of the sum section gives:
\[\Lambda(\phi)\left(\bigwedge_{i\in I}e_i\right) = \sum_{\sigma\in S_I}\sgn(\sigma)\left(\prod_{i\in I}\phi_i^{\sigma(i)}\right)\bigwedge_{i\in I}e_{i} \]
As required.

\subsection{Two important Properties}
There's two more important properties of determinants that are intuitive to prove with the exterior product.
I say intuitive instead of easy because my understanding of the exterior product is somewhat lacking,
but these proofs really motivate me to improve!

\subsubsection{The determinant of a product is the product of the determinants:}
This proof comes from simply applying the outer transform first and using multilinearity to move that determinant out:
\[\begin{aligned}
	\Lambda(\phi\circ\psi)\left(\bigwedge_{i\in I}v_i\right) =&\bigwedge_{i\in I}(\phi\circ\psi)(v_i) \\
	=&\det(\phi)\bigwedge_{i\in I}\psi(v_i) \\
	=&\det(\phi)\det(\psi)\bigwedge_{i\in I}v_i \\
\end{aligned}\]
Note that this result includes $\det(I) = 1$ as a corollary,
but that this could have easily be proved directly by:
\[\Lambda(I)\left(\bigwedge_{i\in I}e_i\right) = \bigwedge_{i\in I}I(e_i) = \bigwedge_{i\in I}e_i\]
	
\subsubsection{Invariant subspaces:}
Let $V_i$ be the $\phi$ invariant subspaces of $V$ indexed by $I$ and let $\phi_i$ be $\phi$ restricted to $V_i$.
From this we get well known isomorphism:
\[V \cong \bigoplus_{i\in I} V_i\]
Another well know isomorphism is:
\[\bigwedge\nolimits^k(W_0\oplus W_1) \cong \bigoplus_{k_0+k_1=k}\bigwedge\nolimits^{k_0}(W_0)\otimes\bigwedge\nolimits^{k_1}(W_1)\]
When $n_k$ is a dimension of $W_k$ this simplifies too:
\[\bigwedge\nolimits^{n_0+n_1}(W_0\oplus W_1) \cong \bigwedge\nolimits^{n_0}(W_0)\otimes\bigwedge\nolimits^{n_1}(W_1)\]
As all other terms in the direct sum include a factor with an exterior power larger than its dimension and hence are zero.
Combining this with the first isomorphism gives:
\[\bigwedge\nolimits^n(V) \cong \bigotimes_{i\in I}\bigwedge\nolimits^{n_i}(V_i)\]
As $\phi$ induced $\Lambda(\phi)$ on $\bigwedge\nolimits^n(V)$ so does $\phi_i$ induce $\Lambda(\phi_i)$ on $\bigwedge\nolimits^{n_i}(V_i)$.
Furthermore,
$\Lambda(\phi)$ induces an endomorphism on $\bigotimes_{i\in I}\bigwedge\nolimits^{n_i}(V_i)$ through the above isomorphism with $\bigwedge\nolimits^{n}(V)$.
By the considering the application of this endomorphism where the only non-zero vectors are in the same subspace we obtain the following form\footnote{This phrasing sucks but I can't think of a better one right now.
All the more reason to revise}:
\[\bigotimes_{i\in I}\Lambda(\phi_i)\]
Applying this to some some vector $v\in \bigwedge\nolimits^{n_i}(V_i)$ and define $v_i$ such that:
\[v \cong \bigotimes_{i\in I}v_i\]
We obtain:
\[\begin{aligned} 
	\Lambda(\phi)(v) \cong& \left[\bigotimes_{i\in I}\Lambda(\phi_i)\right]\left(\bigotimes_{i\in I}v_i\right)\\
	\cong& \bigotimes_{i\in I}\Lambda(\phi_i)(v_i)\\
	\cong& \bigotimes_{i\in I}\det(\phi_i)v_i\\
	\cong& \prod_{i\in I}\det(\phi_i)\bigotimes_{i\in I}v_i\\
\end{aligned}\]
Hence the determinant of $\phi$ is equal to the product of the determinants of $\phi_i$.
As a matrix this means that the determinants of a block diagonal matrix is equal to the product of the determinants of those block matrices.

\subsection{Remarks}
I just wanted to remark that I think I may have found my deeper definition of the determinant as this definition has motivation, intuition, and provides a good framework for further proofs.
I don't think I could ask for much more,
but it still doesn't feel complete to me.
Maybe I'm just a little bitter about not seeing this sooner and maybe that feeling will go away if I study exterior products some more.
I hope so, 
as exterior products have been on my to-do list for a while too!

\subsection{Group Action}
After previously deciding that simplifying:
\[\bigwedge_{i\in I}\sum_{j\in J} A_{i,j} = \sum_{\sigma\in J^I}\bigwedge_{i\in I}A_{i,\sigma(i)}\]
Would be too annoying for general $J$ and $I$ it sat in the back of my mind until I realized that $S_I$ acts on $J^I$ by permuting their inputs.
So the sum isn't actually that annoying if we consider the $S_I$ orbits of $J^I$.
\\

Consider $S\subseteq J^I$ such that $S$ has exactly one element in each orbit of $J^I$,
then through the orbits $O_s$ partitioning $J^I$ we obtain:
\[\sum_{\sigma\in J^I}\bigwedge_{i\in I}A_{i,\sigma(i)}=\sum_{s\in S}\sum_{\sigma\in O_s}\bigwedge_{i\in I}A_{i,\sigma(i)}\]
When $S_I$ is finite we can use the Orbit-Stabilizer theorem to see that all elements in the same orbit have the same number of stabilizer and hence are over counted the same about by:
\[\sum_{\sigma \in S_I}A_{i,(\sigma\cdot s)(i)}\]
Hence if we write the stabilizers of $s$ as $H_s$ we get:
\[\bigwedge_{i\in I}\sum_{j\in J} A_{i,j} = \sum_{s\in S} |H_s|^{-1}\sum_{\sigma \in S_I}\bigwedge_{i\in I}A_{i,(\sigma\cdot s)(i)}\]
Expanding $A_{i,j} = a^j_iu_j$ as before we get:
\[\begin{aligned}
\bigwedge_{i\in I}\sum_{j\in J} a^j_iu^j =& \sum_{s\in S} |H_s|^{-1}\sum_{\sigma \in S_I}\left(\prod_{i\in I}a_i^{(\sigma\cdot s)(i)}\right)\bigwedge_{i\in I}u_{(\sigma\cdot s)(i)}\\
=& \sum_{s\in S}|H_s|^{-1}\left[\bigwedge_{i\in I}u_{s(i)}\right]\left[ \sum_{\sigma \in S_I}\sgn(\sigma)\left(\prod_{i\in I}a_i^{(\sigma\cdot s)(i)}\right)\right]\\
\end{aligned}\]
Observe that:
\begin{itemize}
\item The wedge product factor vanishes unless $s$ is injective.
\item All injective functions only have the identity permutation as a stabilizer.
\item All injective functions with the same range are in the same orbit.
\item Only injective functions with the same range are in the same orbit.
\end{itemize}
The first result is trivial.
The middle two come from considering two injective functions $f:I\rightarrow J$ and $g:I\rightarrow J$ and a permutation $\sigma \in S_I$ such that:
\[g(\sigma(i)) = f(i)\]
The final result follows from combining the middle two with the Orbit-Stabilizer theorem and lets us restrict the previous sum to:
\[\bigwedge_{i\in I}\sum_{j\in J} a^j_iu^j =\sum_{s\in S'}\left[\bigwedge_{i\in I}u_{s(i)}\right]\left[ \sum_{\sigma \in S_I}\sgn(\sigma)\left(\prod_{i\in I}a_i^{(\sigma\cdot s)(i)}\right)\right]\]
Where $S'$ is a set of injective functions of $J^I$ such that all ranges are present and each function has a unique range,
which can also be thought of as a sum over subsets of $J$ of size $|I|$.

\subsection{What about $S_J$?}
What about $S_J$?
It also acts on $J^I$ but by changing output instead of input\footnote{
And hence $S_J\times S_I$ acts of $J^I$ by permuting inputs and changing outputs}?
This was actually the first group action I tried,
but the problem was that $S_J$ doesn't simply permute the outputs.
Consider $\phi: C_2\rightarrow C_3$ and $\sigma\in S_{C_3}$ such that:
\[\phi(1) = 1,\quad \phi(2) = 2,\quad \sigma = (1)(23)\]
This gives:
\[(\sigma\cdot\phi)(1) =1,\quad(\sigma\cdot\phi)(2)=3\]
Since the changes are more extreme than permutations this group action is unable to simply:
\[\bigwedge_{i\in I}A_{i,(\sigma\cdot s)(i)}\]
So isn't particularly useful for our problem.
Do however observe that that all injective functions are in the same orbit and this result can be proved similarly to the results from the $S_I$ section.
